{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing (updating) the following libraries for your Sagemaker\n",
    "instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U mxnet-cu101==1.7.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Classificação personalizada para sistemas de recomendação\n",
    "\n",
    "Nas seções anteriores, apenas o feedback explícito foi considerado e os modelos foram treinados e testados nas classificações observadas. Existem dois pontos negativos de tais métodos: primeiro, a maior parte do feedback não é explícito, mas implícito em cenários do mundo real, e o feedback explícito pode ser mais caro de coletar. Em segundo lugar, pares de itens de usuário não observados que podem ser preditivos para os interesses dos usuários são totalmente ignorados, tornando esses métodos inadequados para os casos em que as classificações não estão faltando aleatoriamente, mas devido às preferências dos usuários. Os pares de itens de usuário não observados são uma mistura de feedback negativo real (os usuários não estão interessados nos itens) e valores ausentes (o usuário pode interagir com os itens no futuro). Simplesmente ignoramos os pares não observados na fatoração da matriz e no AutoRec. Claramente, esses modelos são incapazes de distinguir entre pares observados e não observados e geralmente não são adequados para tarefas de classificação personalizada.\n",
    "\n",
    "Para esse fim, uma classe de modelos de recomendação com o objetivo de gerar listas de recomendações classificadas a partir de feedback implícito ganhou popularidade. Em geral, os modelos de classificação personalizados podem ser otimizados com abordagens pontuais, de pares ou de lista. As abordagens pontuais consideram uma única interação por vez e treinam um classificador ou regressor para prever preferências individuais. A fatoração de matriz e o AutoRec são otimizados com objetivos pontuais. As abordagens de pares consideram um par de itens para cada usuário e visam aproximar a ordenação ideal para esse par. Normalmente, as abordagens de pares são mais adequadas para a tarefa de classificação porque a previsão da ordem relativa é uma reminiscência da natureza da classificação. Abordagens listwise aproximam a ordem de toda a lista de itens, por exemplo, otimização direta das medidas de classificação como ganho cumulativo com desconto normalizado ([NDCG](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)). No entanto, as abordagens listwise são mais complexas e intensivas em computação do que as abordagens pontuais ou de pares. Nesta seção, apresentaremos dois objetivos / perdas de pares, perda de classificação personalizada Bayesiana e perda de dobradiça, e suas respectivas implementações.\n",
    "\n",
    "## Perda de classificação personalizada bayesiana e sua implementação\n",
    "\n",
    "A classificação personalizada bayesiana (BPR) :cite:`Rendle.Freudenthaler.Gantner.ea.2009` é uma perda de classificação personalizada aos pares que é derivada do estimador posterior máximo. Ele tem sido amplamente utilizado em muitos modelos de recomendação existentes. Os dados de treinamento do BPR consistem em pares positivos e negativos (valores ausentes). Ele assume que o usuário prefere o item positivo a todos os outros itens não observados.\n",
    "\n",
    "Formalmente, os dados de treinamento são construídos por tuplas na forma de $(u, i, j)$, que representa que o usuário $u$ prefere o item $i$ em vez do item $j$. A formulação bayesiana do BPR que visa maximizar a probabilidade posterior é dada a seguir:\n",
    "\n",
    "$$\n",
    "p(\\Theta \\mid >_u )  \\propto  p(>_u \\mid \\Theta) p(\\Theta)\n",
    "$$\n",
    "\n",
    "Onde $\\Theta$ representa os parâmetros de um modelo de recomendação arbitrário, $>_u$ representa a classificação total personalizada desejada de todos os itens para o usuário $u$. Podemos formular o estimador posterior máximo para derivar o critério de otimização genérico para a tarefa de classificação personalizada.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{BPR-OPT} : &= \\ln p(\\Theta \\mid >_u) \\\\\n",
    "         & \\propto \\ln p(>_u \\mid \\Theta) p(\\Theta) \\\\\n",
    "         &= \\ln \\prod_{(u, i, j \\in D)} \\sigma(\\hat{y}_{ui} - \\hat{y}_{uj}) p(\\Theta) \\\\\n",
    "         &= \\sum_{(u, i, j \\in D)} \\ln \\sigma(\\hat{y}_{ui} - \\hat{y}_{uj}) + \\ln p(\\Theta) \\\\\n",
    "         &= \\sum_{(u, i, j \\in D)} \\ln \\sigma(\\hat{y}_{ui} - \\hat{y}_{uj}) - \\lambda_\\Theta \\|\\Theta \\|^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "onde $D := \\{(u, i, j) \\mid i \\in I^+_u \\wedge j \\in I \\backslash I^+_u \\}$ é o conjunto de treinamento, com $I^+_u$ denotando os itens que o usuário $u$ gostou, $I$ denotando todos os itens e $I \\backslash I^+_u$ indicando todos os outros itens, exceto itens que o usuário gostou. $\\hat{y}_{ui}$ e $\\hat{y}_{uj}$ são as pontuações previstas do usuário $u$ para os itens $i$ e $j$, respectivamente. O anterior $p(\\Theta)$ é uma distribuição normal com média zero e matriz de variância-covariância $\\Sigma_\\Theta$. Aqui, deixamos $\\Sigma_\\Theta = \\lambda_\\Theta I$.\n",
    "\n",
    "![Ilustração da classificação personalizada bayesiana](../img/rec-ranking.svg)\n",
    "Vamos implementar a classe base `mxnet.gluon.loss.Loss` e substituir o método `forward` para construir a perda de classificação personalizada Bayesiana. Começamos importando a classe Loss e o módulo np.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "origin_pos": 1,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon, np, npx\n",
    "\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 2
   },
   "source": [
    "A implementação da perda do BPR é a seguinte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "origin_pos": 3,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "class BPRLoss(gluon.loss.Loss):\n",
    "    def __init__(self, weight=None, batch_axis=0, **kwargs):\n",
    "        super(BPRLoss, self).__init__(weight=None, batch_axis=0, **kwargs)\n",
    "\n",
    "    def forward(self, positive, negative):\n",
    "        distances = positive - negative\n",
    "        loss = - np.sum(np.log(npx.sigmoid(distances)), 0, keepdims=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "## Hinge Loss e sua implementação\n",
    "\n",
    "A Hinge Loss para classificação tem forma diferente da [Hinge Loss](https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.HingeLoss) fornecida na biblioteca de gluons que é frequentemente usado em classificadores como SVMs. A perda usada para classificação em sistemas de recomendação tem a seguinte forma.\n",
    "\n",
    "$$\n",
    " \\sum_{(u, i, j \\in D)} \\max( m - \\hat{y}_{ui} + \\hat{y}_{uj}, 0)\n",
    "$$\n",
    "\n",
    "onde $m$ é o tamanho da margem de segurança. Seu objetivo é afastar itens negativos de itens positivos. Semelhante ao BPR, visa otimizar a distância relevante entre as amostras positivas e negativas em vez de saídas absolutas, tornando-o adequado para sistemas de recomendação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "origin_pos": 5,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "class HingeLossbRec(gluon.loss.Loss):\n",
    "    def __init__(self, weight=None, batch_axis=0, **kwargs):\n",
    "        super(HingeLossbRec, self).__init__(weight=None, batch_axis=0,\n",
    "                                            **kwargs)\n",
    "\n",
    "    def forward(self, positive, negative, margin=1):\n",
    "        distances = positive - negative\n",
    "        loss = np.sum(np.maximum(- distances + margin, 0))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "Essas duas perdas são intercambiáveis para classificação personalizada na recomendação.\n",
    "\n",
    "## Sumário\n",
    "\n",
    "- Existem três tipos de perdas de classificação disponíveis para a tarefa de classificação personalizada em sistemas de recomendação, a saber, métodos de pontos, pares e listas.\n",
    "- As duas perdas de pares, perda de classificação personalizada Bayesiana e perda de dobradiça, podem ser usadas de forma intercambiável.\n",
    "\n",
    "## Exercícios\n",
    "\n",
    "- Existem variantes de BPR e perda de dobradiça disponíveis?\n",
    "- Você consegue encontrar algum modelo de recomendação que use BPR ou perda de dobradiça?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "mxnet"
    ]
   },
   "source": [
    "[Discussão](https://discuss.d2l.ai/t/402)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "<!--stackedit_data:\n",
    "eyJoaXN0b3J5IjpbLTQ4NTkxNDg0MSw2MzE2NDUxMjddfQ==\n",
    "-->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}